{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasugi2003/Big-Data-Analytics/blob/main/DDL%26DML_using_SQL_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnpa5LgSplhj",
        "outputId": "6104a2e2-69cc-4204-83ba-bbb5c09a5df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285387 sha256=44eb5c26bfef29a664abf90a87e57badf63203170c8558c18f2de920085aa4a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxWZe5ylpgIP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"MySparkApp\").enableHiveSupport().getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F"
      ],
      "metadata": {
        "id": "NMKnHawdqm6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"Alice\", 28), (\"Bob\", 22), (\"Charlie\", 35)]\n",
        "columns = [\"name\", \"age\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()\n",
        "print(type(df))"
      ],
      "metadata": {
        "id": "ik5l0SRHqptq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400eb322-e02f-4dbc-f539-a44946c83168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|   name|age|\n",
            "+-------+---+\n",
            "|  Alice| 28|\n",
            "|    Bob| 22|\n",
            "|Charlie| 35|\n",
            "+-------+---+\n",
            "\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **createOrReplaceTempView()**\n",
        "\n",
        "# **SQL Queries:**It allow you to execute SQL queries against your DataFrame using Spark SQL. You can leverage your SQL skills to interact with and analyze your data stored in DataFrames.\n",
        "\n",
        "# **Integration with SQL Tools:** Temporary views enable you to use various SQL tools and libraries for data analysis and visualization. For example, you can connect SQL clients or visualization tools to Spark and query your data as if it were in a traditional relational database.\n",
        "\n",
        "# **Data Exploration:** Temporary views make it easier to explore and understand your data interactively. You can quickly examine the data, run SQL aggregations, filter, sort, and perform other operations.\n",
        "\n",
        "# **Reusable Queries:** You can define complex data transformations or data preprocessing steps as SQL queries and save them as views.\n",
        "\n",
        "# **Collaboration:** When working in a team, sharing temporary views can help team members understand the structure of the data and the transformations that have been applied."
      ],
      "metadata": {
        "id": "8kO3Y5eGBux6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"people\")\n",
        "result = spark.sql(\"SELECT * FROM people\")\n",
        "result.show()\n",
        "\n",
        "result = spark.sql(\"SELECT * FROM people WHERE age > 25\")\n",
        "result.show()"
      ],
      "metadata": {
        "id": "9KqcDavOqs-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ae912f-f35e-41a7-b3e8-60cb8ad5a511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|   name|age|\n",
            "+-------+---+\n",
            "|  Alice| 28|\n",
            "|    Bob| 22|\n",
            "|Charlie| 35|\n",
            "+-------+---+\n",
            "\n",
            "+-------+---+\n",
            "|   name|age|\n",
            "+-------+---+\n",
            "|  Alice| 28|\n",
            "|Charlie| 35|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using DataFrame API\n",
        "df.write.saveAsTable(\"new_table_name_3\")"
      ],
      "metadata": {
        "id": "FylsgiquqzPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "7p7FgfuUuQHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0d9ff6-52db-45cc-99df-704c25320b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using SQL API\n",
        "spark.sql(\"CREATE TABLE new_table_name_5 AS SELECT * FROM people\")\n",
        "#ddl_statement = \"\"\" CREATE TABLE IF NOT EXISTS employees (id INT,  name STRING,  age INT, salary DOUBLE )\"\"\""
      ],
      "metadata": {
        "id": "h-2q8KjvrEHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c868fccc-1be5-4cc6-e9e6-6cfddabadbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddl_statement = \"\"\" CREATE TABLE IF NOT EXISTS employees (id INT,  name STRING,  age INT, salary DOUBLE )\"\"\"\n",
        "spark.sql(ddl_statement)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee2hj7sMhZ_1",
        "outputId": "4efcaab5-c6c3-4e62-fe90-f561c4000951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using SQL API\n",
        "spark.sql(\"DESCRIBE new_table_name_3\").show()"
      ],
      "metadata": {
        "id": "m2NdaF9stxer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0604956e-4f9b-49fc-9d68-386170e2e23c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-------+\n",
            "|col_name|data_type|comment|\n",
            "+--------+---------+-------+\n",
            "|    name|   string|   null|\n",
            "|     age|   bigint|   null|\n",
            "+--------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using SQL API\n",
        "spark.sql(\"SHOW COLUMNS FROM new_table_name_3\").show()"
      ],
      "metadata": {
        "id": "A0vjjQMKt7m5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a21d46c2-5168-4234-910d-2aecd17caf5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|col_name|\n",
            "+--------+\n",
            "|    name|\n",
            "|     age|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using SQL API\n",
        "spark.sql(\"ALTER TABLE new_table_name_3 ADD COLUMN new_column STRING\")\n"
      ],
      "metadata": {
        "id": "AQ0vu86IrqMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5737a2-6a2e-435d-930a-ca75df13756e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"DESCRIBE new_table_name_3\").show()"
      ],
      "metadata": {
        "id": "mVBNmGNtcUah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec391c75-4a37-4042-ed55-bca8b63f9df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+-------+\n",
            "|  col_name|data_type|comment|\n",
            "+----------+---------+-------+\n",
            "|      name|   string|   null|\n",
            "|       age|   bigint|   null|\n",
            "|new_column|   string|   null|\n",
            "+----------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using DataFrame API\n",
        "#new_data = [(\"David\", 30), (\"Ella\", 25)]\n",
        "#new_df = spark.createDataFrame(new_data, columns)\n",
        "#new_df.write.insertInto(\"new_table_name_1\")"
      ],
      "metadata": {
        "id": "DAEY0RyOsQKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using SQL API\n",
        "spark.sql(\"INSERT INTO TABLE new_table_name_3 VALUES ('Devi', 30,'KEC'), ('arun', 25,'NIT')\")"
      ],
      "metadata": {
        "id": "FIJzsZYKs9Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57229fdf-0b6c-493b-91fa-a40728947704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using SQL API\n",
        "spark.sql(\"SELECT * FROM new_table_name_3\").show()"
      ],
      "metadata": {
        "id": "gntudYqAthwx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ad62cd-ff2c-4fe2-dc12-de51833c36d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+\n",
            "|   name|age|new_column|\n",
            "+-------+---+----------+\n",
            "|   arun| 25|       NIT|\n",
            "|   Devi| 30|       KEC|\n",
            "|    Bob| 22|      null|\n",
            "|Charlie| 35|      null|\n",
            "|  Alice| 28|      null|\n",
            "+-------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Currently spark sql does not support UPDATE statments\n",
        "#spark.sql(\"UPDATE new_table_name_2 SET age = 36 WHERE name = 'Charlie'\")"
      ],
      "metadata": {
        "id": "Jil4DuBM5Wqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.table(\"new_table_name_3\")\n",
        "df.show()"
      ],
      "metadata": {
        "id": "OsMyyJKetSbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f427ee1c-648e-4c3a-b433-5dfd1fff0481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+\n",
            "|   name|age|new_column|\n",
            "+-------+---+----------+\n",
            "|   arun| 25|       NIT|\n",
            "|   Devi| 30|       KEC|\n",
            "|    Bob| 22|      null|\n",
            "|Charlie| 35|      null|\n",
            "|  Alice| 28|      null|\n",
            "+-------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr\n",
        "updated_df = df.withColumn(\"age_plus_5\", expr(\"age + 5\"))\n",
        "updated_df.show()"
      ],
      "metadata": {
        "id": "Qfgc8g1ZuBQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9ccc7b9-06df-4c12-cbc5-51c31e3e545e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+----------+\n",
            "|   name|age|new_column|age_plus_5|\n",
            "+-------+---+----------+----------+\n",
            "|   arun| 25|       NIT|        30|\n",
            "|   Devi| 30|       KEC|        35|\n",
            "|    Bob| 22|      null|        27|\n",
            "|Charlie| 35|      null|        40|\n",
            "|  Alice| 28|      null|        33|\n",
            "+-------+---+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updated_df = df.withColumn(\"age\", expr(\"age + 1\"))\n",
        "updated_df.show()"
      ],
      "metadata": {
        "id": "zu7hLDDIubqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9bb6909-bbb6-42c2-dc0c-f8070ff76972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+\n",
            "|   name|age|new_column|\n",
            "+-------+---+----------+\n",
            "|   arun| 26|       NIT|\n",
            "|   Devi| 31|       KEC|\n",
            "|    Bob| 23|      null|\n",
            "|Charlie| 36|      null|\n",
            "|  Alice| 29|      null|\n",
            "+-------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "updated_df = df.withColumn(\"is_adult\", when(expr(\"age >= 18\"), \"Yes\").otherwise(\"No\"))\n",
        "updated_df.show()"
      ],
      "metadata": {
        "id": "QtD9DLHxwMRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9f3209-08a8-455d-8956-f3403eba7c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+--------+\n",
            "|   name|age|new_column|is_adult|\n",
            "+-------+---+----------+--------+\n",
            "|   arun| 25|       NIT|     Yes|\n",
            "|   Devi| 30|       KEC|     Yes|\n",
            "|    Bob| 22|      null|     Yes|\n",
            "|Charlie| 35|      null|     Yes|\n",
            "|  Alice| 28|      null|     Yes|\n",
            "+-------+---+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "update_condition = (col(\"name\") == \"arun\")\n",
        "# Create a new DataFrame with the updated row\n",
        "updated_df = df.withColumn(\"age\", when(update_condition, 35).otherwise(col(\"age\")))\n",
        "updated_df.show()"
      ],
      "metadata": {
        "id": "Adpy7-lsyfM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3f6885-e71e-4159-a93e-d8e020e9a14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+\n",
            "|   name|age|new_column|\n",
            "+-------+---+----------+\n",
            "|   arun| 35|       NIT|\n",
            "|   Devi| 30|       KEC|\n",
            "|    Bob| 22|      null|\n",
            "|Charlie| 35|      null|\n",
            "|  Alice| 28|      null|\n",
            "+-------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_condition = (col(\"name\") == \"Bob\")\n",
        "# Create a new DataFrame with the updated row\n",
        "updated_df = df.withColumn(\"new_column\", when(update_condition, \"PSG\").otherwise(col(\"new_column\")))\n",
        "updated_df.show()"
      ],
      "metadata": {
        "id": "HA8Cv-BGyv6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca4295d-acb5-4b53-cf3a-1253011d5d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+\n",
            "|   name|age|new_column|\n",
            "+-------+---+----------+\n",
            "|   arun| 25|       NIT|\n",
            "|   Devi| 30|       KEC|\n",
            "|    Bob| 22|       PSG|\n",
            "|Charlie| 35|      null|\n",
            "|  Alice| 28|      null|\n",
            "+-------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_condition = (col(\"name\") == \"Alice\")\n",
        "# Create a new DataFrame with the updated row\n",
        "updated_df = df.withColumn(\"new_column\", when(update_condition, \"PSG\").otherwise(col(\"new_column\")))\n",
        "updated_df.show()"
      ],
      "metadata": {
        "id": "_dBWr5XdzEOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa8849d6-6110-46ad-83ad-25a4f3e94a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+\n",
            "|   name|age|new_column|\n",
            "+-------+---+----------+\n",
            "|   arun| 25|       NIT|\n",
            "|   Devi| 30|       KEC|\n",
            "|    Bob| 22|      null|\n",
            "|Charlie| 35|      null|\n",
            "|  Alice| 28|       PSG|\n",
            "+-------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit\n",
        "job_value = \"Engineer\"\n",
        " # You can change this to your desired job value\n",
        "df_with_job = df.withColumn(\"job\", lit(job_value))\n",
        "df_with_job.show()"
      ],
      "metadata": {
        "id": "-Gz3K9tZ4-CE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4d0cde-c557-4a08-85e6-10fd1ff275ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+--------+\n",
            "|   name|age|new_column|     job|\n",
            "+-------+---+----------+--------+\n",
            "|   arun| 25|       NIT|Engineer|\n",
            "|   Devi| 30|       KEC|Engineer|\n",
            "|    Bob| 22|      null|Engineer|\n",
            "|Charlie| 35|      null|Engineer|\n",
            "|  Alice| 28|      null|Engineer|\n",
            "+-------+---+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define conditions to identify rows to update\n",
        "update_condition = (col(\"name\").isin([\"Alice\", \"Charlie\"]))\n",
        "\n",
        "# Define transformations for the updates\n",
        "job_update_expr = when(update_condition, lit(\"Senior\") + col(\"job\")).otherwise(col(\"job\"))\n",
        "age_update_expr = when(update_condition, col(\"age\") + 5).otherwise(col(\"age\"))\n",
        "\n",
        "# Create a new DataFrame with the updates\n",
        "updated_df = df_with_job.withColumn(\"job\", job_update_expr).withColumn(\"age\", age_update_expr)\n",
        "\n",
        "# Show the updated DataFrame\n",
        "print(\"Updated DataFrame:\")\n",
        "updated_df.show();"
      ],
      "metadata": {
        "id": "_xXRi-nu5Yvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4bfcfbb-bccb-4f83-9e98-cfe30efd3deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated DataFrame:\n",
            "+-------+---+----------+--------+\n",
            "|   name|age|new_column|     job|\n",
            "+-------+---+----------+--------+\n",
            "|   arun| 25|       NIT|Engineer|\n",
            "|   Devi| 30|       KEC|Engineer|\n",
            "|    Bob| 22|      null|Engineer|\n",
            "|Charlie| 40|      null|    null|\n",
            "|  Alice| 33|      null|    null|\n",
            "+-------+---+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define conditions to identify rows to update\n",
        "from pyspark.sql.types import StringType\n",
        "update_condition = (col(\"name\").isin([\"Alice\", \"Charlie\"]))\n",
        "\n",
        "# Define transformations for the updates\n",
        "job_update_expr = when(update_condition, \"Senior Engr\" ).otherwise(col(\"job\")).cast(StringType())\n",
        "age_update_expr = when(update_condition, col(\"age\") + 5).otherwise(col(\"age\"))\n",
        "\n",
        "# Create a new DataFrame with the updates\n",
        "updated_df = df_with_job.withColumn(\"job\", job_update_expr).withColumn(\"age\", age_update_expr)\n",
        "\n",
        "# Show the updated DataFrame\n",
        "print(\"Updated DataFrame:\")\n",
        "updated_df.show()"
      ],
      "metadata": {
        "id": "Lu8Wx05j5_Vz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9cb8c9a-d1d7-48b4-8efe-eab84050e764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated DataFrame:\n",
            "+-------+---+----------+-----------+\n",
            "|   name|age|new_column|        job|\n",
            "+-------+---+----------+-----------+\n",
            "|   arun| 25|       NIT|   Engineer|\n",
            "|   Devi| 30|       KEC|   Engineer|\n",
            "|    Bob| 22|      null|   Engineer|\n",
            "|Charlie| 40|      null|Senior Engr|\n",
            "|  Alice| 33|      null|Senior Engr|\n",
            "+-------+---+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updated_df.write.saveAsTable(\"new_table_name_6\", format=\"parquet\", mode=\"overwrite\")\n"
      ],
      "metadata": {
        "id": "godFfNnHJ_fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#record_to_delete = \"name = 'Bob'\"\n",
        " # Define the condition to identify the record to delete\n",
        "#spark.sql(\"DELETE FROM new_table_name_3 WHERE name='Bob'\")"
      ],
      "metadata": {
        "id": "97xOSIp4Ka1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_df = updated_df.filter(df['name'] != 'Bob')\n",
        "updated_df.show()"
      ],
      "metadata": {
        "id": "Ag8_sEEOP78a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "989f7636-60f3-4f1b-9388-717171595ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+-----------+\n",
            "|   name|age|new_column|        job|\n",
            "+-------+---+----------+-----------+\n",
            "|   arun| 25|       NIT|   Engineer|\n",
            "|   Devi| 30|       KEC|   Engineer|\n",
            "|Charlie| 40|      null|Senior Engr|\n",
            "|  Alice| 33|      null|Senior Engr|\n",
            "+-------+---+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the conditions for record deletion\n",
        "#delete_condition = ((df['name'] == 'Bob') | ((df['age'] >= 30) & (df['job'] == 'Manager')))\n",
        "\n",
        "# Define the conditions for record deletion\n",
        "#delete_condition = ((updated_df['name'] == 'Bob') | ((updated_df['age'] >= 30) | (updated_df['job'] == 'Manager')))\n",
        "delete_condition = ( ((updated_df['age'] >= 30) | (updated_df['job'] == 'Manager')))\n",
        "# Filter the DataFrame to exclude rows matching the conditions\n",
        "filtered_df = updated_df.filter(~delete_condition)\n",
        "filtered_df.show()"
      ],
      "metadata": {
        "id": "heZdvIt3Qd8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6476a5a3-d87b-4fb9-8cae-91d7e9ae6225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+--------+\n",
            "|name|age|new_column|     job|\n",
            "+----+---+----------+--------+\n",
            "|arun| 25|       NIT|Engineer|\n",
            "+----+---+----------+--------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}