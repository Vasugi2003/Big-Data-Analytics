{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZnpM0ULugRfywxoY9tU0S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasugi2003/Big-Data-Analytics/blob/main/window_and_sql_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xormjo186z8D",
        "outputId": "8f5738ee-4e39-4638-981f-728d99043ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=3901824ea337fc0fbe70afa4e2457fa8e04c569429a813c832d785ecc067b997\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"window_functions\").getOrCreate()"
      ],
      "metadata": {
        "id": "fNQYirIb65iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simpleData = ((\"James\", \"Sales\", 3000),\n",
        "    (\"Michael\", \"Sales\", 4600),\n",
        "    (\"Robert\", \"Sales\", 4100),\n",
        "    (\"Maria\", \"Finance\", 3000),\n",
        "    (\"James\", \"Sales\", 3000),\n",
        "    (\"Scott\", \"Finance\", 3300),\n",
        "    (\"Jen\", \"Finance\", 3900),\n",
        "    (\"Jeff\", \"Marketing\", 3000),\n",
        "    (\"Kumar\", \"Marketing\", 2000),\n",
        "    (\"Saif\", \"Sales\", 4100)\n",
        "  )"
      ],
      "metadata": {
        "id": "lMc8GGEJ7jxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns= [\"employee_name\", \"department\", \"salary\"]\n",
        "df = spark.createDataFrame\\\n",
        "          (data = simpleData, schema = columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l09YnJD57s_a",
        "outputId": "9711fd42-5d52-4474-dfe2-6336dca3822f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|James        |Sales     |3000  |\n",
            "|Michael      |Sales     |4600  |\n",
            "|Robert       |Sales     |4100  |\n",
            "|Maria        |Finance   |3000  |\n",
            "|James        |Sales     |3000  |\n",
            "|Scott        |Finance   |3300  |\n",
            "|Jen          |Finance   |3900  |\n",
            "|Jeff         |Marketing |3000  |\n",
            "|Kumar        |Marketing |2000  |\n",
            "|Saif         |Sales     |4100  |\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#row RANKING\n",
        "\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "\n",
        "windowSpec  = Window.partitionBy(\"department\")\\\n",
        "                    .orderBy(\"salary\")\n",
        "df.withColumn(\"row_number\",row_number().over(windowSpec)) \\\n",
        "    .show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES2MuYAD7yjD",
        "outputId": "77483129-6c6b-45e8-a5cb-9dfd668bbc3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----------+\n",
            "|employee_name|department|salary|row_number|\n",
            "+-------------+----------+------+----------+\n",
            "|Maria        |Finance   |3000  |1         |\n",
            "|Scott        |Finance   |3300  |2         |\n",
            "|Jen          |Finance   |3900  |3         |\n",
            "|Kumar        |Marketing |2000  |1         |\n",
            "|Jeff         |Marketing |3000  |2         |\n",
            "|James        |Sales     |3000  |1         |\n",
            "|James        |Sales     |3000  |2         |\n",
            "|Robert       |Sales     |4100  |3         |\n",
            "|Saif         |Sales     |4100  |4         |\n",
            "|Michael      |Sales     |4600  |5         |\n",
            "+-------------+----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rank\n",
        "df.withColumn(\"rank\",rank().over(windowSpec)) \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZbyhh-n85fK",
        "outputId": "e53e1627-a64d-4b21-dd67-09a72510ac8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----+\n",
            "|employee_name|department|salary|rank|\n",
            "+-------------+----------+------+----+\n",
            "|        Maria|   Finance|  3000|   1|\n",
            "|        Scott|   Finance|  3300|   2|\n",
            "|          Jen|   Finance|  3900|   3|\n",
            "|        Kumar| Marketing|  2000|   1|\n",
            "|         Jeff| Marketing|  3000|   2|\n",
            "|        James|     Sales|  3000|   1|\n",
            "|        James|     Sales|  3000|   1|\n",
            "|       Robert|     Sales|  4100|   3|\n",
            "|         Saif|     Sales|  4100|   3|\n",
            "|      Michael|     Sales|  4600|   5|\n",
            "+-------------+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"dens_rank\"\"\"\n",
        "from pyspark.sql.functions import dense_rank\n",
        "df.withColumn(\"dense_rank\",dense_rank().over(windowSpec)) \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASv3Evwa88Sh",
        "outputId": "4dca0aef-a79c-4503-8a12-0f9bf5f716a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----------+\n",
            "|employee_name|department|salary|dense_rank|\n",
            "+-------------+----------+------+----------+\n",
            "|        Maria|   Finance|  3000|         1|\n",
            "|        Scott|   Finance|  3300|         2|\n",
            "|          Jen|   Finance|  3900|         3|\n",
            "|        Kumar| Marketing|  2000|         1|\n",
            "|         Jeff| Marketing|  3000|         2|\n",
            "|        James|     Sales|  3000|         1|\n",
            "|        James|     Sales|  3000|         1|\n",
            "|       Robert|     Sales|  4100|         2|\n",
            "|         Saif|     Sales|  4100|         2|\n",
            "|      Michael|     Sales|  4600|         3|\n",
            "+-------------+----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" percent_rank \"\"\"\n",
        "from pyspark.sql.functions import percent_rank\n",
        "df.withColumn(\"percent_rank\",percent_rank().over(windowSpec)) \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2bKvfP59CU5",
        "outputId": "04a712af-f26a-472d-ade7-80b8bd4c016c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+------------+\n",
            "|employee_name|department|salary|percent_rank|\n",
            "+-------------+----------+------+------------+\n",
            "|        Maria|   Finance|  3000|         0.0|\n",
            "|        Scott|   Finance|  3300|         0.5|\n",
            "|          Jen|   Finance|  3900|         1.0|\n",
            "|        Kumar| Marketing|  2000|         0.0|\n",
            "|         Jeff| Marketing|  3000|         1.0|\n",
            "|        James|     Sales|  3000|         0.0|\n",
            "|        James|     Sales|  3000|         0.0|\n",
            "|       Robert|     Sales|  4100|         0.5|\n",
            "|         Saif|     Sales|  4100|         0.5|\n",
            "|      Michael|     Sales|  4600|         1.0|\n",
            "+-------------+----------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"ntile\"\"\"\n",
        "from pyspark.sql.functions import ntile\n",
        "df.withColumn(\"ntile\",ntile(3).over(windowSpec)) \\\n",
        "    .show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7UAM1pJ9Fbh",
        "outputId": "c254db9b-86ba-4aa1-9d36-9addac2153f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+-----+\n",
            "|employee_name|department|salary|ntile|\n",
            "+-------------+----------+------+-----+\n",
            "|        Maria|   Finance|  3000|    1|\n",
            "|        Scott|   Finance|  3300|    2|\n",
            "|          Jen|   Finance|  3900|    3|\n",
            "|        Kumar| Marketing|  2000|    1|\n",
            "|         Jeff| Marketing|  3000|    2|\n",
            "|        James|     Sales|  3000|    1|\n",
            "|        James|     Sales|  3000|    1|\n",
            "|       Robert|     Sales|  4100|    2|\n",
            "|         Saif|     Sales|  4100|    2|\n",
            "|      Michael|     Sales|  4600|    3|\n",
            "+-------------+----------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" cume_dist \"\"\"\n",
        "from pyspark.sql.functions import cume_dist\n",
        "df.withColumn(\"cume_dist\",cume_dist().over(windowSpec)) \\\n",
        "   .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjzDvcZJ9IxR",
        "outputId": "aa5dfe6f-821d-4b4b-f8da-a83f589c20f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+------------------+\n",
            "|employee_name|department|salary|         cume_dist|\n",
            "+-------------+----------+------+------------------+\n",
            "|        Maria|   Finance|  3000|0.3333333333333333|\n",
            "|        Scott|   Finance|  3300|0.6666666666666666|\n",
            "|          Jen|   Finance|  3900|               1.0|\n",
            "|        Kumar| Marketing|  2000|               0.5|\n",
            "|         Jeff| Marketing|  3000|               1.0|\n",
            "|        James|     Sales|  3000|               0.4|\n",
            "|        James|     Sales|  3000|               0.4|\n",
            "|       Robert|     Sales|  4100|               0.8|\n",
            "|         Saif|     Sales|  4100|               0.8|\n",
            "|      Michael|     Sales|  4600|               1.0|\n",
            "+-------------+----------+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"lag\"\"\"\n",
        "from pyspark.sql.functions import lag\n",
        "df.withColumn(\"lag\",lag(\"salary\",2).over(windowSpec)) \\\n",
        "      .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI687Z0d9K5C",
        "outputId": "ead47af7-cdb9-4cdc-aab4-eaf411a36e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----+\n",
            "|employee_name|department|salary| lag|\n",
            "+-------------+----------+------+----+\n",
            "|        Maria|   Finance|  3000|NULL|\n",
            "|        Scott|   Finance|  3300|NULL|\n",
            "|          Jen|   Finance|  3900|3000|\n",
            "|        Kumar| Marketing|  2000|NULL|\n",
            "|         Jeff| Marketing|  3000|NULL|\n",
            "|        James|     Sales|  3000|NULL|\n",
            "|        James|     Sales|  3000|NULL|\n",
            "|       Robert|     Sales|  4100|3000|\n",
            "|         Saif|     Sales|  4100|3000|\n",
            "|      Michael|     Sales|  4600|4100|\n",
            "+-------------+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " \"\"\"lead\"\"\"\n",
        " from pyspark.sql.functions import lead\n",
        "df.withColumn(\"lead\",lead(\"salary\",1).over(windowSpec)) \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6Ww5r6mA9em",
        "outputId": "f200cb4d-c441-421a-9ae3-d6bc6682a98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----+\n",
            "|employee_name|department|salary|lead|\n",
            "+-------------+----------+------+----+\n",
            "|        Maria|   Finance|  3000|3300|\n",
            "|        Scott|   Finance|  3300|3900|\n",
            "|          Jen|   Finance|  3900|NULL|\n",
            "|        Kumar| Marketing|  2000|3000|\n",
            "|         Jeff| Marketing|  3000|NULL|\n",
            "|        James|     Sales|  3000|3000|\n",
            "|        James|     Sales|  3000|4100|\n",
            "|       Robert|     Sales|  4100|4100|\n",
            "|         Saif|     Sales|  4100|4600|\n",
            "|      Michael|     Sales|  4600|NULL|\n",
            "+-------------+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "windowSpecAgg  = Window.partitionBy(\"department\")\n",
        "from pyspark.sql.functions import col,avg,sum,min,max,row_number\n",
        "df.withColumn(\"row\",row_number().over(windowSpec)) \\\n",
        "  .withColumn(\"avg\", avg(col(\"salary\")).over(windowSpecAgg)) \\\n",
        "  .withColumn(\"sum\", sum(col(\"salary\")).over(windowSpecAgg)) \\\n",
        "  .withColumn(\"min\", min(col(\"salary\")).over(windowSpecAgg)) \\\n",
        "  .withColumn(\"max\", max(col(\"salary\")).over(windowSpecAgg)) \\\n",
        "  .where(col(\"row\") == 1)\\\n",
        "  .select(\"department\",\"row\",\"avg\",\"sum\",\"min\",\"max\") \\\n",
        "  .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WLGGdDIBAGo",
        "outputId": "6a7d9edf-1b5c-4dd1-cfb6-0b3e55e7e34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+-----+----+----+\n",
            "|department|row|   avg|  sum| min| max|\n",
            "+----------+---+------+-----+----+----+\n",
            "|   Finance|  1|3400.0|10200|3000|3900|\n",
            "| Marketing|  1|2500.0| 5000|2000|3000|\n",
            "|     Sales|  1|3760.0|18800|3000|4600|\n",
            "+----------+---+------+-----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "windowSpecAgg  = Window.partitionBy(\"department\")\n",
        "from pyspark.sql.functions import col,avg,sum,min,max,row_number\n",
        "df.withColumn(\"row\",row_number().over(windowSpec)) \\\n",
        " .withColumn(\"avg\", avg(col(\"salary\")).over(windowSpecAgg)) \\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkRfmlBVBH-G",
        "outputId": "bc37c1dd-2154-4ef4-b670-83243b9d8c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+---+------+\n",
            "|employee_name|department|salary|row|   avg|\n",
            "+-------------+----------+------+---+------+\n",
            "|        Maria|   Finance|  3000|  1|3400.0|\n",
            "|        Scott|   Finance|  3300|  2|3400.0|\n",
            "|          Jen|   Finance|  3900|  3|3400.0|\n",
            "|        Kumar| Marketing|  2000|  1|2500.0|\n",
            "|         Jeff| Marketing|  3000|  2|2500.0|\n",
            "|        James|     Sales|  3000|  1|3760.0|\n",
            "|        James|     Sales|  3000|  2|3760.0|\n",
            "|       Robert|     Sales|  4100|  3|3760.0|\n",
            "|         Saif|     Sales|  4100|  4|3760.0|\n",
            "|      Michael|     Sales|  4600|  5|3760.0|\n",
            "+-------------+----------+------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xRM5hhJQBQZf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}