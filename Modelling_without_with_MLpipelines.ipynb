{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasugi2003/Big-Data-Analytics/blob/main/Modelling_without_with_MLpipelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_-uOR9E9omu",
        "outputId": "15946863-fe7f-4062-bcaf-c93061a88f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=38b7b289e642af121600faf2c6bbd33c58dbe6c2fc53bea1e991e72685e870dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR4v-reJuz8K"
      },
      "source": [
        "## StringIndexer transformation to the DataFrame df.\n",
        "## indexer.fit(df): This part fits (trains) the StringIndexer on the DataFrame df. It computes the mapping of distinct string values in the \"price\" column to unique numerical indices.\n",
        "## .transform(df): After fitting the StringIndexer, you use the transform method to apply the transformation to the DataFrame df. This replaces the values in the \"price\" column with their corresponding numerical indices and stores the result in a new column named \"price_Index. **bold text**\"\n",
        "### The transformed DataFrame is assigned to the variable train_df1. It contains the original data from cdf1 along with the newly added \"categoryIndex\" column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljnJvzUD2hXN"
      },
      "source": [
        "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx6Ar7eXxrUR"
      },
      "source": [
        "# In a single feature vector, each component represents the value of a feature. For example, if you have a dataset of houses with features like \"square footage,\" \"number of bedrooms,\" and \"number of bathrooms,\" a single feature vector for a house might look like this: [2000, 3, 2], where the first value represents square footage, the second value represents the number of bedrooms, and the third value represents the number of bathrooms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IKwePX8D-0t",
        "outputId": "9dfc38d6-664f-43f3-9db3-397315337aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- date: timestamp (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- bedrooms: double (nullable = true)\n",
            " |-- bathrooms: double (nullable = true)\n",
            " |-- sqft_living: integer (nullable = true)\n",
            " |-- sqft_lot: integer (nullable = true)\n",
            " |-- floors: double (nullable = true)\n",
            " |-- waterfront: integer (nullable = true)\n",
            " |-- view: integer (nullable = true)\n",
            " |-- condition: integer (nullable = true)\n",
            " |-- sqft_above: integer (nullable = true)\n",
            " |-- sqft_basement: integer (nullable = true)\n",
            " |-- yr_built: integer (nullable = true)\n",
            " |-- yr_renovated: integer (nullable = true)\n",
            " |-- street: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- statezip: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- date: timestamp (nullable = true)\n",
            " |-- price: integer (nullable = false)\n",
            " |-- bedrooms: integer (nullable = true)\n",
            " |-- bathrooms: integer (nullable = true)\n",
            " |-- sqft_living: integer (nullable = true)\n",
            " |-- sqft_lot: integer (nullable = true)\n",
            " |-- floors: integer (nullable = true)\n",
            " |-- waterfront: integer (nullable = true)\n",
            " |-- view: integer (nullable = true)\n",
            " |-- condition: integer (nullable = true)\n",
            " |-- sqft_above: integer (nullable = true)\n",
            " |-- sqft_basement: integer (nullable = true)\n",
            " |-- yr_built: integer (nullable = true)\n",
            " |-- yr_renovated: integer (nullable = true)\n",
            " |-- street: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- statezip: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            "\n",
            "+-------------------+-----+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+-------------+--------+-------+-----------+--------------------+\n",
            "|               date|price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|         city|statezip|country|price_index|            features|\n",
            "+-------------------+-----+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+-------------+--------+-------+-----------+--------------------+\n",
            "|2014-05-02 00:00:00|    0|       2|        1|        800|    4850|     1|         0|   0|        4|       800|            0|    1944|           0|4801-4899 6th Ave NW|      Seattle|WA 98107|    USA|        0.0|[2.0,1.0,800.0,48...|\n",
            "|2014-05-02 00:00:00|    0|       2|        1|        850|    6174|     1|         0|   0|        4|       850|            0|    1950|        1983|     121 NE 147th St|    Shoreline|WA 98155|    USA|        0.0|[2.0,1.0,850.0,61...|\n",
            "|2014-05-02 00:00:00|    0|       2|        1|        880|    6380|     1|         0|   0|        3|       880|            0|    1938|        1994|      522 NE 88th St|      Seattle|WA 98115|    USA|        0.0|[2.0,1.0,880.0,63...|\n",
            "|2014-05-02 00:00:00|    0|       2|        1|       1210|    9400|     1|         0|   0|        2|      1210|            0|    1949|           0|    7542 21st Ave SW|      Seattle|WA 98106|    USA|        0.0|[2.0,1.0,1210.0,9...|\n",
            "|2014-05-02 00:00:00|    0|       2|        2|       1350|    2560|     1|         0|   0|        3|      1350|            0|    1976|           0|   2616 174th Ave NE|      Redmond|WA 98052|    USA|        0.0|[2.0,2.0,1350.0,2...|\n",
            "|2014-05-02 00:00:00|    0|       3|        1|       1160|    9180|     1|         0|   0|        3|      1160|            0|    1968|        1997|   15804 198th Pl NE|  Woodinville|WA 98077|    USA|        0.0|[3.0,1.0,1160.0,9...|\n",
            "|2014-05-02 00:00:00|    0|       3|        1|       1180|   10277|     1|         0|   0|        3|      1180|            0|    1983|        2009|  12425 415th Ave SE|   North Bend|WA 98045|    USA|        0.0|[3.0,1.0,1180.0,1...|\n",
            "|2014-05-02 00:00:00|    0|       3|        1|       1200|    9720|     1|         0|   0|        4|      1200|            0|    1965|           0|   14034 SE 201st St|         Kent|WA 98042|    USA|        0.0|[3.0,1.0,1200.0,9...|\n",
            "|2014-05-02 00:00:00|    0|       3|        1|       1340|    7912|     1|         0|   0|        3|      1340|            0|    1955|        2005|18810 Densmore Ave N|    Shoreline|WA 98133|    USA|        0.0|[3.0,1.0,1340.0,7...|\n",
            "|2014-05-02 00:00:00|    0|       3|        1|       1370|    5858|     1|         0|   0|        3|      1370|            0|    1987|        2000|     1605 S 245th Pl|   Des Moines|WA 98198|    USA|        0.0|[3.0,1.0,1370.0,5...|\n",
            "|2014-05-02 00:00:00|    0|       3|        1|       2330|   14892|     1|         0|   0|        3|      1970|          360|    1980|           0|    1833 220th Pl NE|    Sammamish|WA 98074|    USA|        0.0|[3.0,1.0,2330.0,1...|\n",
            "|2014-05-02 00:00:00|    0|       3|        2|       1580|   16215|     1|         0|   0|        4|      1580|            0|    1978|        2000|   4460 332nd Ave SE|    Fall City|WA 98024|    USA|        0.0|[3.0,2.0,1580.0,1...|\n",
            "|2014-05-02 00:00:00|    0|       3|        2|       1770|    1235|     3|         0|   0|        3|      1600|          170|    2007|           0|      1156 N 93rd St|      Seattle|WA 98103|    USA|        0.0|[3.0,2.0,1770.0,1...|\n",
            "|2014-05-02 00:00:00|    0|       3|        2|       1770|    2875|     2|         0|   0|        3|      1770|            0|    1990|        2009|    4458 51st Ave SW|      Seattle|WA 98116|    USA|        0.0|[3.0,2.0,1770.0,2...|\n",
            "|2014-05-02 00:00:00|    0|       3|        2|       1930|   11947|     1|         0|   0|        4|      1930|            0|    1966|           0|26206-26214 143rd...|         Kent|WA 98042|    USA|        0.0|[3.0,2.0,1930.0,1...|\n",
            "|2014-05-02 00:00:00|    0|       3|        2|       1960|   13100|     1|         0|   2|        5|      1650|          310|    1957|           0|    17825 4th Ave SW|Normandy Park|WA 98166|    USA|        0.0|[3.0,2.0,1960.0,1...|\n",
            "|2014-05-02 00:00:00|    0|       3|        2|       1970|   35100|     2|         0|   0|        4|      1970|            0|    1977|           0|   26069 SE 154th St|     Issaquah|WA 98027|    USA|        0.0|[3.0,2.0,1970.0,3...|\n",
            "|2014-05-02 00:00:00|    0|       3|        2|       2000|    8030|     1|         0|   0|        4|      1000|         1000|    1963|           0|     857 170th Pl NE|     Bellevue|WA 98008|    USA|        0.0|[3.0,2.0,2000.0,8...|\n",
            "|2014-05-02 00:00:00|    0|       3|        2|       2090|   10834|     1|         0|   0|        4|      1360|          730|    1987|           0|27736 23rd Avenue...|  Federal Way|WA 98003|    USA|        0.0|[3.0,2.0,2090.0,1...|\n",
            "|2014-05-02 00:00:00|    0|       3|        2|       2540|    5050|     2|         0|   0|        3|      2540|            0|    2006|           0|29734 215th Terra...|         Kent|WA 98042|    USA|        0.0|[3.0,2.0,2540.0,5...|\n",
            "+-------------------+-----+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+-------------+--------+-------+-----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Area under ROC curve: 0.8725\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import IntegerType\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder.appName(\"HousePriceClassification\").getOrCreate()\n",
        "\n",
        "# Load data\n",
        "filepath = \"/content/houseprice.csv\"\n",
        "df = spark.read.csv(filepath, header=True, inferSchema=True)\n",
        "# df.show()\n",
        "df.printSchema()\n",
        "# Preprocess data\n",
        "# Convert \"price\" column to numeric based on condition\n",
        "df = df.withColumn(\"price\", F.when(F.col(\"price\") > 600000, 1).otherwise(0)\\\n",
        "                   .cast(IntegerType()))\n",
        "\n",
        "# Cast selected columns to IntegerType\n",
        "int_columns = ['bathrooms', 'bedrooms', 'sqft_living', 'sqft_lot', 'floors', \\\n",
        "               'sqft_basement']\n",
        "\n",
        "\n",
        "for col_name in int_columns:\n",
        "    df = df.withColumn(col_name, df[col_name].cast(IntegerType()))\n",
        "df.printSchema()\n",
        "# Split data\n",
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=11)\n",
        "train_df.count()\n",
        "test_df.count()//902\n",
        "# Label encoding\n",
        "  #indexer.fit(df)\n",
        "      # It computes the mapping of distinct string values\n",
        "      # in the \"price\" column to unique numerical indices\n",
        "  #transform(df):\n",
        "    #replaces the values in the \"price\" column with their corresponding\n",
        "    #numerical indices and stores the result in a new column named \"price_Index.\n",
        "\n",
        "price_indexer = StringIndexer(inputCol=\"price\", outputCol=\"price_index\")\n",
        "\n",
        "train_df = price_indexer.fit(train_df).transform(train_df)\n",
        "\n",
        "# Feature vector assembly\n",
        "input_cols = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'sqft_basement']\n",
        "vector_assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
        "train_df = vector_assembler.transform(train_df)\n",
        "train_df.show()\n",
        "\n",
        "# Create and train Decision Tree Classifier model\n",
        "dt_model = DecisionTreeClassifier(labelCol=\"price_index\", featuresCol=\"features\")\n",
        "dt_model = dt_model.fit(train_df)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"price_index\")\n",
        "\n",
        "# Transform and predict on test data\n",
        "test_df = test_df.withColumn(\"price\", F.when(F.col(\"price\") > 600000, 1).otherwise(0).cast(IntegerType()))\n",
        "test_df = price_indexer.fit(test_df).transform(test_df)\n",
        "test_df = vector_assembler.transform(test_df)\n",
        "test_predictions = dt_model.transform(test_df)\n",
        "\n",
        "# Display evaluation results\n",
        "accuracy = evaluator.evaluate(test_predictions)\n",
        "print(f\"Area under ROC curve: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V12FPv544cPD",
        "outputId": "bd035cad-eb36-4c78-a5f2-529995ec6048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+\n",
            "|price|prediction|\n",
            "+-----+----------+\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Accuracy: 0.7871396895787139\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import when\n",
        "from pyspark.sql.types import IntegerType\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder.appName(\"YourAppName\").getOrCreate()\n",
        "\n",
        "# Read data from CSV\n",
        "filepath = \"/content/houseprice.csv\"\n",
        "df1 = spark.read.csv(filepath, header=True)\n",
        "\n",
        "# Convert \"price\" column to numeric based on condition and cast to IntegerType\n",
        "df1 = df1.withColumn(\"price\", when(F.col(\"price\") > 600000, 1).otherwise(0).cast(IntegerType()))\n",
        "\n",
        "# Define input columns and output column for VectorAssembler\n",
        "inputColumns = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'sqft_basement']\n",
        "outputColumn = \"features\"\n",
        "\n",
        "# Cast the selected input columns to IntegerType\n",
        "for col_name in inputColumns:\n",
        "    df1 = df1.withColumn(col_name, df1[col_name].cast(IntegerType()))\n",
        "\n",
        "# Create a StringIndexer for \"price\" column\n",
        "price_indexer = StringIndexer(inputCol=\"price\", outputCol=\"priceIndex\")\n",
        "# Create a VectorAssembler for input features\n",
        "vector_assembler = VectorAssembler(inputCols=inputColumns, outputCol=outputColumn)\n",
        "# Create a DecisionTreeClassifier\n",
        "dt_model = DecisionTreeClassifier(labelCol=\"price\", featuresCol=outputColumn)\n",
        "\n",
        "# Define the pipeline stages\n",
        "stages = [price_indexer, vector_assembler, dt_model]\n",
        "# Create a pipeline\n",
        "pipeline = Pipeline(stages=stages)\n",
        "# Split data into train and test\n",
        "(train_df2, test_df2) = df1.randomSplit([0.8, 0.2], seed=11)\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "final_pipeline = pipeline.fit(train_df2)\n",
        "# Make predictions on the test data\n",
        "test_predictions_from_pipeline = final_pipeline.transform(test_df2)\n",
        "\n",
        "# Show the first 5 rows of predictions\n",
        "test_predictions_from_pipeline.select(\"price\", \"prediction\").show(5)\n",
        "\n",
        "# Evaluate the model and perform further analysis as needed\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "# Evaluate the model using accuracy (or other appropriate metric for multi-class classification)\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "# Define the evaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "# Calculate the accuracy\n",
        "accuracy = evaluator.evaluate(test_predictions_from_pipeline)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_koLh2vhIcFN",
        "outputId": "e14d1376-ba8d-4bdd-eafb-209b2ec5ce87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.85       624\n",
            "           1       0.71      0.52      0.60       278\n",
            "\n",
            "    accuracy                           0.79       902\n",
            "   macro avg       0.76      0.71      0.73       902\n",
            "weighted avg       0.78      0.79      0.78       902\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Calculate accuracy\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(test_predictions_from_pipeline)\n",
        "\n",
        "# Convert the PySpark DataFrame to a Pandas DataFrame\n",
        "test_predictions_pd = test_predictions_from_pipeline.select(\"price\", \"prediction\").toPandas()\n",
        "\n",
        "# Get the true labels and predicted labels as lists\n",
        "true_labels = test_predictions_pd[\"price\"].tolist()\n",
        "predicted_labels = test_predictions_pd[\"prediction\"].tolist()\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}