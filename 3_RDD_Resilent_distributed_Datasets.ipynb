{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasugi2003/Big-Data-Analytics/blob/main/3_RDD_Resilent_distributed_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WjAogjR3exK",
        "outputId": "57f21665-7325-478e-95e3-5f1abdb0b822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285388 sha256=b256fb611cb5ab4613b0d84e8a36cee1379ddb18b840c2f89ac2efb29c970020\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "spark = SparkContext.getOrCreate()\n",
        "data = [\"scala\",\"java\",\"hadoop\",\"spark\",\"pyspark\",\"spark vs hadoop\"]\n",
        "rdd = spark.parallelize(data)\n",
        "counts = rdd.count()\n",
        "print(\"elements = %d\"% (counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-ci4Upm3jr2",
        "outputId": "3f810c53-a84f-4cb4-8115-0442a0cdd8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elements = 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collect = rdd.collect()\n",
        "print(\"Elements of rdd = %s\"%(collect))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_2rWDon5IMY",
        "outputId": "6e71fd4f-4eca-4cee-cbc2-cde57e11cd06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements of rdd = ['scala', 'java', 'hadoop', 'spark', 'pyspark', 'spark vs hadoop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for each loop\n",
        "\n",
        "rdd = spark.parallelize(\n",
        "    [\"scala\", \"java\",\"python\",\"R\",\"pyspark\",\"hadoop\"]\n",
        "\n",
        ")\n",
        "def f(x):\n",
        "  print(x)\n",
        "\n",
        "rdd.foreach(f)"
      ],
      "metadata": {
        "id": "_buZxN4E6BLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "spark = SparkContext.getOrCreate()\n",
        "data = [\"scala\",\"java\",\"hadoop\",\"spark\",\"pyspark\",\"spark vs hadoop\"]\n",
        "rdd = spark.parallelize(data)\n",
        "data_filter = rdd.filter(lambda x: 'spark' in x)\n",
        "filtered = data_filter.collect()\n",
        "print(\"elements = %s\"% (filtered))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-PJC7iP6BTW",
        "outputId": "d1c4c50a-c547-4744-af97-3d5fc93c1d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elements = ['spark', 'pyspark', 'spark vs hadoop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mapping\n",
        "rdd = spark.parallelize(\n",
        "    [\"scala\", \"java\",\"python\",\"R\",\"pyspark\",\"hadoop\"]\n",
        "\n",
        ")\n",
        "word_map = rdd.map(lambda x: (x,1))\n",
        "mapping = word_map.collect()\n",
        "print(mapping)\n",
        "print(\"key value pair = %s\"%(mapping))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TbQpOOw6BXA",
        "outputId": "f8249107-aa0f-4dbc-85b9-a18737b8994f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('scala', 1), ('java', 1), ('python', 1), ('R', 1), ('pyspark', 1), ('hadoop', 1)]\n",
            "key value pair = [('scala', 1), ('java', 1), ('python', 1), ('R', 1), ('pyspark', 1), ('hadoop', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from operator import add\n",
        "sc= SparkContext.getOrCreate()\n",
        "rdd = sc.parallelize([1,2,3,4,5])\n",
        "sum = rdd.reduce(add)\n",
        "print(\"Adding elements -> %i\" % (sum))\n"
      ],
      "metadata": {
        "id": "X1JRu5Tk6BaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1afa2957-cd55-4ae3-f7c0-e6bd6e3c9255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding elements -> 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd= spark.parallelize([\"scala\",\"java\",\"Haddop\",\"spark\",\"pyspark\",\"akka\",\"pyspark and spark\"])\n",
        "rdd.cache()\n",
        "caching = rdd.persist().is_cached\n",
        "print(\"cached words = %s\"%(caching))"
      ],
      "metadata": {
        "id": "o6TtMvW86BdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e47192-e405-4a73-e104-0cf2375da6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cached words = True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRtZvJS86Bgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_3OlxRGY6BkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3c2QZK_n6Bnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kl1X_dTp6BrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u-_y2dYK6Bu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eD8fFUJx6Bye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z0U1U_gd6B4X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}