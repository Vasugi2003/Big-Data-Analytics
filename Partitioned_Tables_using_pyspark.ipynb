{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasugi2003/Big-Data-Analytics/blob/main/Partitioned_Tables_using_pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZdIYJsMVUui",
        "outputId": "02448633-71ca-4163-a701-74bee9ff7aa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285387 sha256=e52cba926c742f7fd7595fb4f70df887e5b98582f1450adcecb3292990545441\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .appName(\"PySparkTransformationsExample\")\\\n",
        "        .getOrCreate()\n"
      ],
      "metadata": {
        "id": "2WA-ZAADWer8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.option(\"header\",True).csv(\"zipcodes.csv\")\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiU6KZgxWWKg",
        "outputId": "3f8ef793-27c6-40a9-d59d-0a58a05f21d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- RecordNumber: string (nullable = true)\n",
            " |-- Zipcode: string (nullable = true)\n",
            " |-- ZipCodeType: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- LocationType: string (nullable = true)\n",
            " |-- Lat: string (nullable = true)\n",
            " |-- Long: string (nullable = true)\n",
            " |-- Xaxis: string (nullable = true)\n",
            " |-- Yaxis: string (nullable = true)\n",
            " |-- Zaxis: string (nullable = true)\n",
            " |-- WorldRegion: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- LocationText: string (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            " |-- Decommisioned: string (nullable = true)\n",
            " |-- TaxReturnsFiled: string (nullable = true)\n",
            " |-- EstimatedPopulation: string (nullable = true)\n",
            " |-- TotalWages: string (nullable = true)\n",
            " |-- Notes: string (nullable = true)\n",
            "\n",
            "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
            "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|   Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|        Notes|\n",
            "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
            "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        FALSE|           null|               null|      null|         null|\n",
            "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        FALSE|           null|               null|      null|         null|\n",
            "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
            "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72| -97.31| -0.1|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        FALSE|           null|               null|      null|         null|\n",
            "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
            "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|        Ft Worth, TX|   NA-US-TX-FT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
            "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US| Urb Eugene Rice, PR|NA-US-PR-URB EUGE...|        FALSE|           null|               null|      null|         null|\n",
            "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|33.37|-111.64| -0.3|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14962|              26883| 563792730|no NWS data, |\n",
            "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|33.38|-111.84|-0.31|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14374|              25446| 471000465|         null|\n",
            "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|30.69| -81.92| 0.12|-0.85| 0.51|         NA|     US|        Hilliard, FL|   NA-US-FL-HILLIARD|        FALSE|           3922|               7443| 133112149|         null|\n",
            "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|28.96| -82.41| 0.11|-0.86| 0.48|         NA|     US|          Holder, FL|     NA-US-FL-HOLDER|        FALSE|           null|               null|      null|         null|\n",
            "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|30.72| -86.67| 0.04|-0.85| 0.51|         NA|     US|            Holt, FL|       NA-US-FL-HOLT|        FALSE|           1207|               2190|  36395913|         null|\n",
            "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|28.78| -82.61| 0.11|-0.86| 0.48|         NA|     US|       Homosassa, FL|  NA-US-FL-HOMOSASSA|        FALSE|           null|               null|      null|         null|\n",
            "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
            "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|   Sect Lanausse, PR|NA-US-PR-SECT LAN...|        FALSE|           null|               null|      null|         null|\n",
            "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|33.97| -85.55| 0.06|-0.82| 0.55|         NA|     US|   Spring Garden, AL|NA-US-AL-SPRING G...|        FALSE|           null|               null|      null|         null|\n",
            "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|33.77| -86.47| 0.05|-0.82| 0.55|         NA|     US|     Springville, AL|NA-US-AL-SPRINGVILLE|        FALSE|           4046|               7845| 172127599|         null|\n",
            "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|34.37| -87.69| 0.03|-0.82| 0.56|         NA|     US|     Spruce Pine, AL|NA-US-AL-SPRUCE PINE|        FALSE|            610|               1209|  18525517|         null|\n",
            "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE| 36.4| -80.56| 0.13|-0.79| 0.59|         NA|     US|        Ash Hill, NC|   NA-US-NC-ASH HILL|        FALSE|            842|               1666|  28876493|         null|\n",
            "|       76512|  27203|   STANDARD|           ASHEBORO|   NC|       PRIMARY|35.71| -79.81| 0.14|-0.79| 0.58|         NA|     US|        Asheboro, NC|   NA-US-NC-ASHEBORO|        FALSE|           8355|              15228| 215474318|         null|\n",
            "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#partitionBy()\n",
        "df.write.option(\"header\",True).partitionBy(\"state\")\\\n",
        "  .mode(\"overwrite\").csv(\"tmp2/zipcodes-state2\")\n",
        "#we have a total of 6 different states hence, it creates 6 directories as shown below. The name of the sub-directory would be the partition column and its value (partition column=value).\n",
        "#While writing the data as partitions, PySpark eliminates the partition column on the data file and adds partition column & value to the folder name, hence it saves some space on storage."
      ],
      "metadata": {
        "id": "Vqjkv8foWx6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#partitionBy() multiple columns\n",
        "df.write.option(\"header\",True).partitionBy(\"state\",\"city\")\\\n",
        "  .mode(\"overwrite\").csv(\"tmp2/zipcodes-state-city\")"
      ],
      "metadata": {
        "id": "Ca4-UVslRTXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use repartition() and partitionBy() together\n",
        "df.repartition(2).write.option(\"header\",True).partitionBy(\"state\")\\\n",
        "  .mode(\"overwrite\").csv(\"tmp2/zipcodes-state-v2\")"
      ],
      "metadata": {
        "id": "UzBV1EVKcg3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8LhMgdUDz7Xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#partitionBy() control number of partitions\n",
        "# Data Skew – Control Number of Records per Partition File\n",
        "#This is particularly helpful when your data is skewed (Having some partitions with very low records\n",
        "# and other partitions with high number of records)\n",
        "df.write.option(\"header\",True) \\\n",
        "        .option(\"maxRecordsPerFile\", 3) \\\n",
        "        .partitionBy(\"state\") \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .csv(\"/tmp/zipcodes-state_2\")\n"
      ],
      "metadata": {
        "id": "S7eTkynHeGt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfSinglePart = spark.read.option(\"header\",True)\\\n",
        "  .csv(\"tmp2/zipcodes-state-city/state=AL/city=SPRINGVILLE\")\n",
        "dfSinglePart.printSchema()\n",
        "dfSinglePart.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAvZf6rjfHJ4",
        "outputId": "3bb3cd1d-71eb-486d-f501-e4f4f5d5eac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- RecordNumber: string (nullable = true)\n",
            " |-- Zipcode: string (nullable = true)\n",
            " |-- ZipCodeType: string (nullable = true)\n",
            " |-- LocationType: string (nullable = true)\n",
            " |-- Lat: string (nullable = true)\n",
            " |-- Long: string (nullable = true)\n",
            " |-- Xaxis: string (nullable = true)\n",
            " |-- Yaxis: string (nullable = true)\n",
            " |-- Zaxis: string (nullable = true)\n",
            " |-- WorldRegion: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- LocationText: string (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            " |-- Decommisioned: string (nullable = true)\n",
            " |-- TaxReturnsFiled: string (nullable = true)\n",
            " |-- EstimatedPopulation: string (nullable = true)\n",
            " |-- TotalWages: string (nullable = true)\n",
            " |-- Notes: string (nullable = true)\n",
            "\n",
            "+------------+-------+-----------+------------+-----+------+-----+-----+-----+-----------+-------+---------------+--------------------+-------------+---------------+-------------------+----------+-----+\n",
            "|RecordNumber|Zipcode|ZipCodeType|LocationType|  Lat|  Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|   LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|Notes|\n",
            "+------------+-------+-----------+------------+-----+------+-----+-----+-----+-----------+-------+---------------+--------------------+-------------+---------------+-------------------+----------+-----+\n",
            "|       54355|  35146|   STANDARD|     PRIMARY|33.77|-86.47| 0.05|-0.82| 0.55|         NA|     US|Springville, AL|NA-US-AL-SPRINGVILLE|        FALSE|           4046|               7845| 172127599| null|\n",
            "+------------+-------+-----------+------------+-----+------+-----+-----+-----+-----------+-------+---------------+--------------------+-------------+---------------+-------------------+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parqDF = spark.read.option(\"header\",True) \\\n",
        "                  .csv(\"/content/tmp2/zipcodes-state-v2/\")\n",
        "parqDF.createOrReplaceTempView(\"ZIPCODE\")\n",
        "spark\\\n",
        "    .sql(\"select * from ZIPCODE  where state='AL' and city = 'SPRINGVILLE'\") \\\n",
        "    .show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6NQYDZMmLzs",
        "outputId": "d4249a56-7351-4019-d6f5-bea3793214a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------+-----------+-----------+------------+-----+------+-----+-----+-----+-----------+-------+---------------+--------------------+-------------+---------------+-------------------+----------+-----+-----+\n",
            "|RecordNumber|Zipcode|ZipCodeType|       City|LocationType|  Lat|  Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|   LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|Notes|state|\n",
            "+------------+-------+-----------+-----------+------------+-----+------+-----+-----+-----+-----------+-------+---------------+--------------------+-------------+---------------+-------------------+----------+-----+-----+\n",
            "|       54355|  35146|   STANDARD|SPRINGVILLE|     PRIMARY|33.77|-86.47| 0.05|-0.82| 0.55|         NA|     US|Springville, AL|NA-US-AL-SPRINGVILLE|        FALSE|           4046|               7845| 172127599| null|   AL|\n",
            "+------------+-------+-----------+-----------+------------+-----+------+-----+-----+-----+-----------+-------+---------------+--------------------+-------------+---------------+-------------------+----------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://sparkbyexamples.com/pyspark/pyspark-partitionby-example/"
      ],
      "metadata": {
        "id": "cNKxhYsA1mtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " How to Choose a Partition Column When Writing to File system?           \n",
        "              Let’s assume you have a US census table that contains zip code, city, state, and other columns. Creating a partition on the state, splits the table into around 50 partitions, when searching for a zipcode within a state (state=’CA’ and zipCode =’92704′) results in faster as it needs to scan only in a state=CA partition directory.\n",
        "\n",
        "Partition on zipcode may not be a good option as you might end up with too many partitions.\n",
        "\n",
        "Another good example of partition is on the Date column. Ideally, you should partition on Year/Month but not on a date."
      ],
      "metadata": {
        "id": "N2ZEunEe21MX"
      }
    }
  ]
}